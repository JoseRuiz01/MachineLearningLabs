{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "from sklearn.model_selection import train_test_split\n",
    "import math\n",
    "import random\n",
    "from random import uniform\n",
    "from sklearn import preprocessing\n",
    "from sklearn import tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 1 : simple dataset with 2 features (same as previous TP)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X1</th>\n",
       "      <th>X2</th>\n",
       "      <th>Y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.697580</td>\n",
       "      <td>0.684940</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.478690</td>\n",
       "      <td>0.633770</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.057028</td>\n",
       "      <td>0.918860</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.593890</td>\n",
       "      <td>0.494880</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.229840</td>\n",
       "      <td>-0.411550</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>0.460250</td>\n",
       "      <td>0.012427</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>-0.046659</td>\n",
       "      <td>0.816520</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>0.322000</td>\n",
       "      <td>0.692250</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>-0.524770</td>\n",
       "      <td>0.209800</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>-0.599650</td>\n",
       "      <td>-0.418860</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>118 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           X1        X2  Y\n",
       "0   -0.697580  0.684940  0\n",
       "1   -0.478690  0.633770  1\n",
       "2    0.057028  0.918860  0\n",
       "3   -0.593890  0.494880  0\n",
       "4    0.229840 -0.411550  1\n",
       "..        ...       ... ..\n",
       "113  0.460250  0.012427  1\n",
       "114 -0.046659  0.816520  1\n",
       "115  0.322000  0.692250  1\n",
       "116 -0.524770  0.209800  1\n",
       "117 -0.599650 -0.418860  0\n",
       "\n",
       "[118 rows x 3 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We will load the data that is in the file 'donnees_exo1.txt'\n",
    "data = pd.read_csv('donnees_exo1.txt', sep = ' ')\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train / Valid / Test split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here I propose you to use the same split as mine so that you can observe the same things as I observed (the data set is very small so the theoretical things explained in CM might not always occur with such a small dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train, data_test = train_test_split(data, test_size = 0.3, random_state = 4)\n",
    "data_valid, data_test = train_test_split(data_test, test_size = 0.5, random_state = 4)\n",
    "# 82 examples in train, 18 in valid and 18 in test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting the training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "color_map = matplotlib.colors.ListedColormap(pd.Series(['blue', 'red']))\n",
    "fig = plt.figure(figsize=  (8,8))\n",
    "fig = plt.scatter(data_train.iloc[:,0], data_train.iloc[:,1], c = data_train.Y, cmap = color_map, marker='+')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fitting a decision tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The basic decision tree can be obtained easily by this command\n",
    "dt = tree.DecisionTreeClassifier().fit(data_train.iloc[:,:2],data_train.Y)\n",
    "# More advanced options can be inserted into the 'DecisionTreeClassifier' function (we will see some later)\n",
    "# The 'fit' function needs to have 2 parameters (at least) : \n",
    "# - the set of features describing the examples (here the 2 first columns of our train set)\n",
    "# - the associated labels (classes, here the column 'Y' of our train set)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing the obtained tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(21, 9))\n",
    "tree.plot_tree(dt, filled=True)\n",
    "# The 'plot_tree' function outputs two things : \n",
    "# - a text version of the tree (where are written the informations about all the nodes of the tree)\n",
    "# - a graphical representation of the tree (right branches correspond to answer 'no' and left branches 'yes')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Questions :\n",
    "   - What is the Gini index at the root of the tree ? \n",
    "   - How many leaves are there in this tree ? You should see that all the leaves are 'pure' (i.e., only 1 class is present inside the leaves). This is normal for the basic version of a decision tree"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Questions : \n",
    "- Look at the first example of the training set. What are its features and its class ?\n",
    "- How this example is classified by the tree (by just looking at the tree)? Is the tree making a right prediction ? Is it normal ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We can obtain automatically the prediction of the tree for any example with the 'predict' command (as for logistic regression):\n",
    "dt.predict(data_train.iloc[:1,:2]) # here I ask to predict the first example of the train set, need to give its features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question : Using the 'score' command (as for logistic regression), compute the performance score of this tree on the trainig set. You should obtain a particular score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question : Same question but on the validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function 'draw_boundary_tree' plots the decision boundary (only for dataset with 2 features of course).\n",
    "As in previous TP, you need to give some parameters : \n",
    " - the model, here a tree\n",
    " - the dataset of examples that you want to plot together with the boundary\n",
    " - and coordinates for min and max of x-axis and y-axis\n",
    "An example of the use of this function with our data and tree is given right after"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_boundary_tree(model, data, x_min, x_max, y_min, y_max):\n",
    "    h = 0.05\n",
    "    xx, yy = np.meshgrid(np.arange(x_min, x_max, h), np.arange(y_min, y_max, h))\n",
    "    zz = np.c_[xx.ravel(), yy.ravel()]\n",
    "    zz = pd.DataFrame(zz)\n",
    "    zz2 = zz\n",
    "    pred_zz= pd.Series(model.predict(zz2))\n",
    "    color_map = matplotlib.colors.ListedColormap(pd.Series(['blue', 'red']))\n",
    "    fig = plt.figure(figsize=  (8,8))\n",
    "    fig = plt.scatter(zz.iloc[:,0], zz.iloc[:,1], c = pred_zz, cmap = color_map, marker='+')\n",
    "    fig = plt.scatter(data.iloc[:,0], data.iloc[:,1], s = 50, c = data.iloc[:,2], cmap = color_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "draw_boundary_tree(dt, data_train, -1.2, 1.2, -1.2, 1.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question : Why this boundary is typical to a decision tree ? What kind of phenomenon can you observe here ?"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pruning the tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As explained in the CM, the basic decision tree is only composed of pure leaves which might sometimes lead to a model that is too complex. In order to simplify the model, we can prune the tree. \n",
    "One way to do this in Python (with the sklearn package) is to use a complexity factor alpha that penalizes the number of nodes in the tree. \n",
    "\n",
    "If alpha = 0, there is no penalty for the number of nodes. It is as the basic model. But when alpha increases, it gives more penalty to the number of nodes and so tries to create tree with less nodes (and so with leaves that are not always pure). \n",
    "\n",
    "The values of alpha that needs to be considered depend on the dataset. We can obtain all the possible values of alpha for a given dataset by the following commands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = tree.DecisionTreeClassifier() # first declare a tree\n",
    "path = clf.cost_complexity_pruning_path(data_train.iloc[:,0:2], data_train.Y) # then ask for all the possible values \n",
    "# of alpha to prune this tree (depends on the training set)\n",
    "path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should see above that, for our training set, 11 different trees can be obtained, from basic tree (alpha = 0 -> no pruning) to maximum pruning (here alpha = 0.05405405). \n",
    "\n",
    "The values above correspond to the different values of alpha that we can use ('ccp_alpha') and the associated average impurity in the leaves ('impurities'). When alpha = 0, no impurity -> normal. \n",
    "\n",
    "Below, you'll find how to plot the level of impurity VS the values of alpha. As alpha increases, the impurity increases as well. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ccp_alphas, impurities = path.ccp_alphas, path.impurities\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(ccp_alphas, impurities)\n",
    "plt.xlabel(\"effective alpha\")\n",
    "plt.ylabel(\"total impurity of leaves\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want to build a tree with a particular value of alpha, you need to specify it into the 'DecisionTreeClassifier' function (see below)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_pruned = tree.DecisionTreeClassifier(ccp_alpha=path.ccp_alphas[2]).fit(data_train.iloc[:,0:2], data_train.Y)\n",
    "# Here I asked for the third value from all the possible alpha (the first one is 0, already done with the basic tree)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Questions : \n",
    "- Plot the obtained tree to visualize the difference with the one obtained above (alpha = 0). In particular, you should see impure leaves\n",
    "- Visualize the decision boundary of this new tree\n",
    "- Compute its performance on the training set and on the validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question : \n",
    "- Using a for loop on the values of alpha (path.ccp_alphas), compute the prediction scores of all the possible pruned trees on the training set and on the validation set (you can store the scores in 2 different vectors).\n",
    "- Plot on a graph these scores VS alpha (2 different curves). \n",
    "- You can also visualize the pruned tree and the decision boundary to see how it evolves with pruning.\n",
    "- Which pruned tree will you choose here ? Draw its decision boundary\n",
    "- Estimate its generalization error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 2 : with a real dataset of handwritten digits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will now work with a real dataset containing black and white images of handwritten digits.\n",
    "\n",
    "Each image has 28*28 pixels (of value 0 or 1, for white or black) and contains one handwritten digit (from 0 to 9).\n",
    "The file 'cp_sample.csv' contains 1000 such images (in vectorial form, i.e. only the pixel values and the label).\n",
    "\n",
    "Below, the command to load this dataset.\n",
    "\n",
    "You see that it contains 1000 rows (1 row -> 1 image) and 785 columns (784 pixel values, and the label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist = pd.read_csv('cp_sample.csv', sep=';')\n",
    "mnist.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question : What is the distribution of the labels in this dataset (i.e., how many images have label 0, label 1, ...) ?\n",
    "\n",
    "*Hint : value_counts()*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The values of pixels and label for one image can be obtained by the command:\n",
    "mnist.iloc[0,:] # First image of the dataset\n",
    "# You can see that the label is in the column 'label' and the other columns are pixel0, pixel1, etc...\n",
    "# This first image represents the digit 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# It is possible to see an image from its pixel values using the following command:\n",
    "plt.imshow(mnist.iloc[0,1:].to_numpy().reshape(28,28),cmap = 'Greys')\n",
    "# Here is the first image, representing a 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question : Split this dataset into train / validation / test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Questions : \n",
    " - Fit a decision tree to the training set (don't try to plot it, it might be huge)\n",
    " - What is the prediction score of this tree on the training set ? on the validation set ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should see that the prediction score of the decision tree on the validation set is not extremely high.\n",
    "We will try to improve the performance by pruning the tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Questions : \n",
    "   - As in the first exercise, try all the possible pruning of the tree and select the most adapted one.\n",
    "   - What is the score of the selected tree on the training set ? on the validation set ?\n",
    "   - What is the estimation of the generalization error of this tree ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trying the model on your own written image "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can try the model that you obtained above to recognize written digit of your own. For that, you need to create a 28*28 png file where you draw a digit. Save the file and then you can use the following function to visalize your image and convert it to the format that the model will accept (784-dimensional vector). \n",
    "\n",
    "See example below with the file 'test_0.png' that I have created"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "import skimage.io\n",
    "def read_myimage(f):\n",
    "    myimage = skimage.io.imread(f, as_gray=True)\n",
    "    i0 = np.where(myimage==0)\n",
    "    i1 = np.where(myimage == 1)\n",
    "    myimage[i0] = 1\n",
    "    myimage[i1] = 0\n",
    "    plt.imshow(myimage, cmap='Greys')\n",
    "    return myimage.reshape(1,28*28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use this code if your image is already 28x28 and binary (black and white)\n",
    "myim = read_myimage('test_0.png')\n",
    "dt.predict(myim) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use this code if your image is neither 28x28 nor binary (black and white)\n",
    "\n",
    "from skimage.transform import resize\n",
    "\n",
    "myim = myimage = skimage.io.imread('test_0.jpeg', as_gray=True)\n",
    "\n",
    "fig, axes = plt.subplots(ncols=4, figsize=(12, 3))\n",
    "ax = axes.ravel()\n",
    "ax[0] = plt.subplot(1, 4, 1)\n",
    "ax[1] = plt.subplot(1, 4, 2)\n",
    "ax[2] = plt.subplot(1, 4, 3)\n",
    "ax[3] = plt.subplot(1, 4, 4)\n",
    "\n",
    "# show the original image\n",
    "ax[0].imshow(myimage, cmap=plt.cm.gray)\n",
    "ax[0].set_title('Original')\n",
    "ax[0].axis('off')\n",
    "\n",
    "# Binarize the image\n",
    "thresh = 0.60*np.max(myimage) # 60% of the maximum intensity may be enough to detect the black pixels\n",
    "i0 = np.where(myimage <= thresh) \n",
    "i1 = np.where(myimage > thresh)\n",
    "myimage[i0] = 0 # Black pixels\n",
    "myimage[i1] = 1 # White pixels\n",
    "\n",
    "ax[1].imshow(myimage, cmap=plt.cm.gray)\n",
    "ax[1].set_title('Binarized')\n",
    "ax[1].axis('off')\n",
    "\n",
    "# Get the bounding box coordinates of the digit\n",
    "top, bottom = np.min(i0[0]), np.max(i0[0])\n",
    "left, right = np.min(i0[1]), np.max(i0[1])\n",
    "myimage = myimage[top:bottom, left:right]\n",
    "ax[2].imshow(myimage, cmap=plt.cm.gray)\n",
    "ax[2].set_title('Cropped')\n",
    "ax[2].axis('off')\n",
    "\n",
    "# pad the image to get a squared image\n",
    "h, w = myimage.shape\n",
    "if h > w:\n",
    "    pad = (h - w) // 2\n",
    "    myimage = np.pad(myimage, ((1,1),(pad, pad)), 'constant', constant_values=1)\n",
    "elif w > h:\n",
    "    pad = (w - h) // 2\n",
    "    myimage = np.pad(myimage, ((pad, pad),(1,1)), 'constant', constant_values=1)\n",
    "\n",
    "ax[2].imshow(myimage, cmap=plt.cm.gray)\n",
    "ax[2].set_title('Squared')\n",
    "ax[2].axis('off')\n",
    "\n",
    "# resize the image to 28x28 and binarize again\n",
    "myimage = resize(myimage, (28,28), anti_aliasing=True)\n",
    "thresh = 0.9*np.max(myimage) \n",
    "i0 = np.where(myimage <= thresh) \n",
    "i1 = np.where(myimage > thresh)\n",
    "myimage[i0] = 0\n",
    "myimage[i1] = 1\n",
    "ax[3].imshow(myimage, cmap=plt.cm.gray)\n",
    "ax[3].set_title('Resized')\n",
    "ax[3].axis('off')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic regression for the same task"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results obtained with the best tree should not be very interesting. You can try now with logistic regression and estimate the generalization error of logistic regression on this dataset to see that it performs much better.\n",
    "\n",
    "Questions : \n",
    "- Fit a logistic regression model to the training set and estimate the generalization error (no need to add non-linear features as here the features are 0 or 1, so polynomial faeatures will not help)\n",
    "- Use this model to predict the image 'test_0.png'. Should work better!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using Histogram of Oriented Gradients (HOG) representation rather than pixel values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the previous section, we have directy used the pixel values as features to perform classification. For complex images, the pixel values might not be adapted to this task. Better image representations can be used in order to transform an image into a feature vector that contains informations about the content of an image (colors, orientations for instance). You will have an introduction about this in the INV course (with Thomas Corpetti, soon).\n",
    "In this part of the TP, we will use a quite simple image representation to perform classification : the HOG representation (some informations can be found here : \n",
    "https://scikit-image.org/docs/dev/auto_examples/features_detection/plot_hog.html)\n",
    "\n",
    "This representation computes histograms about the orientations of the gradients that are found in an image. Actually, it splits the image into sub-images (blocks) and compute one histogram per block. The number of orientations and blocks are parameters of the HOG representation. \n",
    "For instance, with our images (28*28), if we ask for blocks of 14*14 pixels and 8 different orientations (angles), it will produce 4 (4 blocks of size 14*14 in the image) histograms of size 8 (8 orientations), hence a vector of size 32.\n",
    "\n",
    "Each image will now be represented with this vector of size 32 (rather than the 784 pixel values). \n",
    "\n",
    "Below, an example of how to produce this vector from an image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.feature import hog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "myimage = mnist.iloc[0,1:] # first image of the mnist dataset (784 pixel values)\n",
    "myimage_hog = hog(myimage.to_numpy().reshape(28,28,1), orientations=8, pixels_per_cell=(14,14), cells_per_block=(1,1))\n",
    "myimage_hog"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see that the result is a vector of size 32 (4 blocks, and histograms with 8 orientations). Each histogram is normalized so that the sum of square values in the histogram equals 1. You can check that the sum of the 8 first values (squared) equals 1. \n",
    "\n",
    "In the following, we will transform each image of our dataset using this represenation and then use this new dataset as input to classifiers, hoping that it will improve the classification performance. \n",
    "\n",
    "The next two cells transform the training, validation and test set with the HOG representation (blocks of 14*14 pixels and 8 orientations, you can change these parameters later)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_hog(row, ori, cell):\n",
    "    return(pd.Series(hog(row.iloc[1:].to_numpy().reshape(28,28,1), orientations=ori, pixels_per_cell=(cell, cell), cells_per_block=(1,1))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "hog_train = data_train.apply(my_hog, axis=1, args=(8,14))\n",
    "hog_valid= data_valid.apply(my_hog, axis=1, args=(8,14))\n",
    "hog_test = data_test.apply(my_hog, axis=1, args=(8,14))\n",
    "hog_train['label'] = data_train.label\n",
    "hog_valid['label'] = data_valid.label\n",
    "hog_test['label'] = data_test.label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hog_train\n",
    "# you see here that each image of the training set is now a vector of length 32"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exercise : Apply the procedure used in this TP to find the best tree adapted to this new dataset, and estimate its generalization error. Is it better than with raw images ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question : You can try now to use a richer representation (more blocks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question : Now use the logistic regression on this new dataset and estimate the generalization error. Conclusion ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
